{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time I have replace the original input with the embedding generated by pytorch-biggraph and found the quality is much worse than the original method. I found the loss does not decrease. \n",
    "\n",
    "Now I found that is mainly because the embedding vector is real number and the loss function is binary cross entropy which is supposed to work with binary integers. I have processed the embedding vector with sigmoid function and round to the closest integer. This time I have observed the loss decrease but the quality of output does not obviously improved.\n",
    "\n",
    "Besides that I have tried to directly use the embedding to replace the output of the graph-level RNN and use as the initial hidden state of edge-level RNN. Because in original method the output of the graph-level RNN can be considered as an embedding of the graph. \n",
    "\n",
    "![image.png](img/Report19-09-16_2.jpg)\n",
    "\n",
    "But the result quality is almost the same as the first replacement.\n",
    "\n",
    "|Method     | Original GraphRNN | GraphRNN with pytorch biggraph embedding as input of first RNN |GraphRNN with pytorch biggraph embedding as input of second RNN|\n",
    "| :---        |    :----:   |    :----:   |          ---: |\n",
    "|Degree     | 0.1631650749      | 1.852754479   |1.574217785|\n",
    "|Clustering coef.   | 0.03183506654       |1.981700998      |1.974965171|\n",
    "|Orbit counts   | 0.06887923342        |1.323235293      |1.49117802|\n",
    "\n",
    "\n",
    "So I think directly replace original GraphRNN input with embedding generated by other methods may not be suitable for our case. Since the expected input of GraphRNN is an adjacent matrix and embedding does not necessarily have corresponding information.\n",
    "\n",
    "Currently I'm thinking about that GraphRNN will generate a batch of graphs and they are generated from the same model trained with a set of graphs with similar properties. Therefore, theses generated graphs are supposed to have similar properties. So if we may merge them together, we can get a much larger graph and hopefully it could still maintain the similar properties. At first we may try some straightforward way to merge them. The current evaluate program provided by the author of GraphRNN may not support evaluate graphs of larger scale. Next step I will look into it and try to find out a way to merge and evaulate the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
